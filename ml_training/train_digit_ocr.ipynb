{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# https://github.com/gereshes/Blog-Companion/blob/master/keras2PyTorch-Hard/createKears.py\n",
    "\n",
    "import numpy as np\n",
    "# from keras.models import Sequential, load_model\n",
    "# from keras.layers import Dense\n",
    "# from keras.wrappers.scikit_learn import KerasRegressor\n",
    "# from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# import matplotlib.pyplot as plt\n",
    "# import random\n",
    "# from scipy.integrate import odeint\n",
    "# import scipy.io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# import torchvision.transforms as transforms\n",
    "import torch.optim as optim # optimzer\n",
    "\n",
    "import random\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'mnist_train_imgs'\n",
    "\n",
    "# TODO: Use all images\n",
    "data_dirs = [ \n",
    "             'mnist_test_imgs',\n",
    "             'mnist_train_imgs'\n",
    "             'saved_digits'\n",
    "             ]\n",
    "\n",
    "category_labels = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "\n",
    "train_dir = os.path.join('mnist_train_imgs')\n",
    "\n",
    "test_dir = os.path.join('mnist_test_imgs')\n",
    "# test_dir = os.path.join('saved_digits')\n",
    "\n",
    "\n",
    "img_size = (28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Add horizontal/vertical smearing to the images.\n",
    "# TODO: Add A TINY BIT of random pixel noise to the images.\n",
    "# TODO: Identify the min / max image fill of the dataset.\n",
    "\n",
    "def random_alignment(img):\n",
    "    ax1sums = np.sum(img, axis=0)\n",
    "    up_shift = np.argmax(ax1sums>0)\n",
    "    down_shift = np.argmax(ax1sums[::-1]>0)\n",
    "    \n",
    "    ax2sums = np.sum(img, axis=1)\n",
    "    left_shift = np.argmax(ax2sums>0)\n",
    "    right_shift = np.argmax(ax2sums[::-1]>0)\n",
    "\n",
    "    random_y = random.randint(-up_shift, down_shift)\n",
    "    random_x = random.randint(-left_shift, right_shift)\n",
    "    \n",
    "    return np.roll(img, (random_x, random_y), axis=(0, 1))\n",
    "\n",
    "def transform(img, randomize=False):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    _, img = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    if randomize:\n",
    "        img = random_alignment(img)\n",
    "        \n",
    "    img = torch.tensor(img)\n",
    "    img = img.unsqueeze(0)\n",
    "    img = img.float()\n",
    "    img = img / 255\n",
    "    return img\n",
    "\n",
    "# TODO: Add up/down/left/right shift to the images.\n",
    "# TODO: Flip images? Flip certain numbers?\n",
    "# TODO: Rework to allow multiple data directories. (mnist + saved digits)\n",
    "        \n",
    "# Define a custom pytorch Dataset class\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, img_size, transform, labels, randomize=False):\n",
    "        self.root_dir = root_dir\n",
    "        self.image_files = [str(p.relative_to(root_dir)) for p in Path(root_dir).rglob(\"*.[Pp][Nn][Gg]\")]\n",
    "        self.randomize = randomize\n",
    "        self.transform = transform\n",
    "        self.img_size = img_size\n",
    "        self.labels = labels # NOTE: Not enforced upon loaded images, may crash if extra directories are around\n",
    "    \n",
    "    # Define the length of the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    # Define the getitem function to return images and labels\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.root_dir, self.image_files[idx])\n",
    "\n",
    "        # Open image, apply transforms.\n",
    "        image = cv2.imread(image_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image, randomize=self.randomize)\n",
    "            \n",
    "        label = os.path.split(self.image_files[idx])[0]\n",
    "        target = torch.tensor(self.labels.index(label))\n",
    "        #Create a dictionary with the image and label\n",
    "        sample = {'image': image, 'target': target, 'label': label}\n",
    "        \n",
    "        return sample\n",
    "\n",
    "    # def shuffle(self):\n",
    "    #     random.shuffle(self.image_files)\n",
    "    \n",
    "#Create the dataloader for training and test dat\n",
    "train_data = CustomDataset(root_dir=train_dir, img_size=img_size, transform=transform, labels=category_labels)\n",
    "test_data = CustomDataset(root_dir=test_dir, img_size=img_size, transform=transform, labels=category_labels, randomize=False)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Digit_OCR_CNN(\n",
       "  (conv1): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop1): Dropout(p=0.25, inplace=False)\n",
       "  (fc1): Linear(in_features=1176, out_features=128, bias=True)\n",
       "  (drop2): Dropout(p=0.25, inplace=False)\n",
       "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (drop3): Dropout(p=0.25, inplace=False)\n",
       "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class Digit_OCR_CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Digit_OCR_CNN, self).__init__()\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 3, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(3, 6, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.drop1 = nn.Dropout(0.25)\n",
    "        self.fc1 = nn.Linear(6 * 14 * 14, 128)\n",
    "        self.drop2 = nn.Dropout(0.25)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.drop3 = nn.Dropout(0.25)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.conv1(state))\n",
    "        # x = self.pool(F.relu(self.conv1(state)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # print(x.size())\n",
    "        x = self.drop1(x)\n",
    "        x = x.view(-1, 6 * 14 * 14)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop2(x)\n",
    "\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.drop3(x)\n",
    "        x = F.log_softmax(self.fc3(x), dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "net = Digit_OCR_CNN()\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(device)\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.NLLLoss()\n",
    "# criterion = nn.KLDivLoss() # Boolean values\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.AdamW(net.parameters(), lr=0.001)#, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    50] loss: 0.166\n",
      "[1,   100] loss: 0.164\n",
      "[1,   150] loss: 0.159\n",
      "[1,   200] loss: 0.151\n",
      "[1,   250] loss: 0.151\n",
      "[1,   300] loss: 0.174\n",
      "[1,   350] loss: 0.156\n",
      "[1,   400] loss: 0.158\n",
      "[1,   450] loss: 0.161\n",
      "\tNew best accuracy: 0.97260\n",
      "\t\t> Saving model as best_model.pt\n",
      "[1,   500] loss: 0.145\n",
      "[1,   550] loss: 0.156\n",
      "[1,   600] loss: 0.168\n",
      "[1,   650] loss: 0.153\n",
      "[1,   700] loss: 0.168\n",
      "[1,   750] loss: 0.179\n",
      "[1,   800] loss: 0.151\n",
      "[1,   850] loss: 0.173\n",
      "[1,   900] loss: 0.174\n",
      "\tNew best accuracy: 0.97390\n",
      "\t\t> Saving model as best_model.pt\n",
      "[1,   950] loss: 0.134\n",
      "[1,  1000] loss: 0.177\n",
      "[1,  1050] loss: 0.157\n",
      "[1,  1100] loss: 0.159\n",
      "[1,  1150] loss: 0.161\n",
      "[1,  1200] loss: 0.170\n",
      "[1,  1250] loss: 0.148\n",
      "[1,  1300] loss: 0.140\n",
      "[1,  1350] loss: 0.163\n",
      "[1,  1400] loss: 0.162\n",
      "\tNew best accuracy: 0.97430\n",
      "\t\t> Saving model as best_model.pt\n",
      "[1,  1450] loss: 0.157\n",
      "[1,  1500] loss: 0.151\n",
      "[1,  1550] loss: 0.139\n",
      "[1,  1600] loss: 0.147\n",
      "[1,  1650] loss: 0.150\n",
      "[1,  1700] loss: 0.150\n",
      "[1,  1750] loss: 0.162\n",
      "[1,  1800] loss: 0.163\n",
      "[1,  1850] loss: 0.168\n",
      "Finished Training\n",
      "Time: 31.8636531829834\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def check_best(best_acc):\n",
    "    net.eval()\n",
    "    best_name = 'best_model.pt'\n",
    "    with torch.no_grad():\n",
    "        count = 0\n",
    "        correct = 0\n",
    "        for d in test_loader:\n",
    "            i = d['image']\n",
    "            l = d['label']\n",
    "            r = net(i.to(device))\n",
    "            _, predicted = torch.max(r, 1)\n",
    "            for i, _r in enumerate(predicted):\n",
    "                count += 1\n",
    "                if category_labels[_r] == l[i]:\n",
    "                    correct += 1\n",
    "                else:\n",
    "                    pass\n",
    "        curr_acc = correct/count\n",
    "        if curr_acc > best_acc:\n",
    "            best_acc = curr_acc\n",
    "            torch.save(net.state_dict(), best_name)\n",
    "            print(f'\\tNew best accuracy: {best_acc:.5f}\\n\\t\\t> Saving model as', best_name)\n",
    "    net.train()\n",
    "    return best_acc\n",
    "\n",
    "def train():\n",
    "    \n",
    "    # How low the loss must be to trigger early stopping.\n",
    "    loss_end_thresh = 0.0\n",
    "    # How many consecutive loss values must be below the threshold to trigger early stopping.\n",
    "    consecutive_thresh = 5\n",
    "    # Track how many consecutive loss values have been below the threshold.\n",
    "    thresh_track = 0\n",
    "    \n",
    "    best_interval = int(len(train_loader) / 4) \n",
    "    best_acc = 0.95450\n",
    "\n",
    "    loss_interval = 50\n",
    "    loss_end_thresh = 0.02\n",
    "    consecutive_thresh = 5\n",
    "    thresh_track = 0\n",
    "    for epoch in range(1):  # loop over the dataset multiple times\n",
    "        net.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader):\n",
    "\n",
    "            inputs, targets = data['image'], data['target']\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            # print(outputs.size())\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % loss_interval == loss_interval-1:    # print every 2000 mini-batches\n",
    "                mean_loss = abs(running_loss / loss_interval)\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, mean_loss))\n",
    "                running_loss = 0.0\n",
    "                if mean_loss < loss_end_thresh:\n",
    "                    print(f'Thresh at {thresh_track} of {consecutive_thresh}')\n",
    "                    thresh_track += 1\n",
    "                    if thresh_track > consecutive_thresh:\n",
    "                        best_acc = check_best(best_acc=best_acc)\n",
    "                        return\n",
    "                else:\n",
    "                    thresh_track = 0\n",
    "            if i % best_interval == best_interval-1:\n",
    "                # Check for best\n",
    "                best_acc = check_best(best_acc=best_acc)\n",
    "\n",
    "st = time.time()\n",
    "train()\n",
    "et = time.time()\n",
    "\n",
    "\n",
    "print('Finished Training')\n",
    "print('Time:', et - st)  # milliseconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Digit_OCR_CNN(\n",
       "  (conv1): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop1): Dropout(p=0.25, inplace=False)\n",
       "  (fc1): Linear(in_features=1176, out_features=128, bias=True)\n",
       "  (drop2): Dropout(p=0.25, inplace=False)\n",
       "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (drop3): Dropout(p=0.25, inplace=False)\n",
       "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Digit_OCR_CNN()\n",
    "# load_name = 'models/ability_icon_1_2.pt'\n",
    "load_name = 'best_model.pt'\n",
    "net.load_state_dict(torch.load(load_name))\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 9, 1, 3, 4, 1, 6, 7, 3, 3, 1, 7, 0, 4, 7, 2, 9, 1, 1, 5, 1, 0, 9,\n",
      "        4, 9, 3, 9, 1, 2, 2, 1])\n",
      "tensor([3, 5, 1, 2, 3, 9, 6, 8, 7, 7, 4, 1, 0, 1, 4, 6, 1, 7, 8, 3, 2, 9, 9, 9,\n",
      "        8, 0, 7, 2, 7, 6, 2, 4])\n",
      "tensor([0, 0, 4, 7, 2, 4, 4, 9, 4, 3, 7, 3, 2, 0, 9, 4, 9, 6, 6, 5, 9, 5, 9, 1,\n",
      "        6, 6, 2, 0, 7, 9, 2, 3])\n",
      "tensor([6, 6, 5, 0, 9, 1, 7, 3, 0, 2, 4, 9, 9, 1, 8, 3, 6, 3, 3, 7, 2, 0, 3, 1,\n",
      "        0, 3, 4, 7, 0, 1, 0, 0])\n",
      "tensor([3, 3, 7, 9, 0, 3, 8, 4, 2, 9, 9, 2, 2, 2, 2, 1, 9, 2, 0, 2, 4, 1, 9, 9,\n",
      "        7, 2, 3, 9, 7, 3, 4, 3])\n",
      "tensor([9, 9, 9, 4, 8, 3, 9, 1, 3, 6, 3, 8, 4, 7, 1, 3, 4, 1, 4, 1, 3, 1, 0, 1,\n",
      "        1, 1, 6, 8, 5, 2, 1, 5])\n",
      "tensor([5, 9, 0, 5, 1, 4, 8, 6, 5, 3, 8, 3, 9, 9, 9, 4, 1, 8, 3, 2, 6, 0, 9, 2,\n",
      "        8, 6, 3, 5, 6, 4, 4, 0])\n",
      "tensor([8, 1, 3, 8, 5, 4, 1, 3, 2, 7, 6, 0, 5, 0, 0, 2, 2, 4, 2, 3, 5, 7, 9, 7,\n",
      "        0, 1, 0, 1, 9, 7, 9, 9])\n",
      "tensor([8, 3, 5, 1, 0, 0, 3, 0, 4, 8, 0, 3, 6, 4, 2, 4, 4, 1, 3, 4, 4, 3, 7, 8,\n",
      "        7, 8, 3, 5, 7, 8, 3, 1])\n",
      "tensor([0, 2, 4, 8, 8, 2, 9, 5, 5, 6, 6, 9, 2, 9, 6, 1, 3, 5, 6, 8, 9, 3, 9, 5,\n",
      "        7, 6, 3, 5, 8, 1, 5, 6])\n",
      "tensor([1, 9, 4, 4, 9, 3, 1, 6, 7, 2, 4, 7, 5, 3, 8, 4, 0, 8, 9, 4, 5, 7, 4, 2,\n",
      "        2, 2, 6, 8, 4, 2, 8, 9])\n",
      "tensor([2, 7, 6, 9, 2, 0, 7, 9, 3, 7, 4, 2, 4, 2, 7, 3, 8, 1, 5, 5, 7, 8, 9, 6,\n",
      "        2, 3, 8, 6, 2, 1, 4, 4])\n",
      "tensor([3, 4, 8, 0, 3, 3, 3, 0, 0, 6, 9, 3, 1, 4, 1, 8, 5, 1, 9, 0, 1, 4, 9, 8,\n",
      "        1, 5, 9, 3, 3, 0, 4, 9])\n",
      "tensor([6, 9, 4, 5, 4, 4, 4, 5, 9, 1, 2, 3, 0, 6, 0, 7, 6, 2, 9, 8, 6, 3, 3, 7,\n",
      "        7, 2, 9, 3, 5, 8, 5, 3])\n",
      "tensor([8, 2, 2, 1, 1, 9, 6, 5, 4, 3, 6, 6, 7, 0, 3, 2, 2, 4, 3, 6, 4, 3, 7, 1,\n",
      "        0, 3, 1, 8, 7, 1, 4, 1])\n",
      "tensor([7, 3, 6, 0, 4, 8, 3, 2, 3, 7, 7, 0, 5, 5, 1, 4, 7, 9, 1, 5, 1, 9, 5, 6,\n",
      "        9, 3, 2, 6, 4, 3, 7, 4])\n",
      "tensor([0, 1, 9, 0, 9, 1, 2, 2, 4, 0, 9, 0, 4, 0, 7, 4, 0, 0, 0, 2, 6, 1, 5, 1,\n",
      "        2, 9, 3, 4, 0, 4, 6, 6])\n",
      "tensor([5, 1, 6, 8, 1, 1, 2, 2, 9, 6, 9, 7, 4, 8, 1, 9, 0, 6, 9, 1, 1, 7, 2, 6,\n",
      "        4, 4, 0, 0, 9, 4, 6, 2])\n",
      "tensor([6, 7, 0, 4, 2, 6, 6, 7, 1, 7, 8, 7, 8, 8, 0, 5, 1, 2, 1, 5, 6, 7, 5, 8,\n",
      "        7, 0, 6, 3, 4, 0, 1, 6])\n",
      "tensor([3, 2, 1, 9, 0, 9, 1, 6, 7, 3, 0, 5, 2, 1, 3, 3, 8, 0, 0, 4, 2, 8, 8, 3,\n",
      "        2, 6, 3, 1, 7, 6, 3, 7])\n",
      "tensor([2, 9, 5, 5, 1, 9, 6, 7, 5, 7, 5, 0, 9, 7, 4, 9, 9, 2, 4, 5, 7, 2, 2, 9,\n",
      "        8, 8, 6, 3, 1, 1, 1, 8])\n",
      "tensor([6, 6, 7, 1, 2, 3, 2, 5, 8, 7, 3, 6, 0, 1, 2, 3, 3, 2, 4, 3, 4, 2, 6, 6,\n",
      "        0, 6, 8, 2, 9, 3, 4, 0])\n",
      "tensor([0, 5, 4, 3, 3, 1, 2, 5, 1, 0, 0, 3, 9, 3, 9, 1, 0, 1, 3, 2, 6, 1, 2, 5,\n",
      "        9, 8, 2, 1, 7, 5, 7, 6])\n",
      "tensor([4, 9, 2, 2, 5, 8, 0, 1, 1, 4, 2, 3, 7, 3, 7, 8, 6, 6, 0, 7, 6, 2, 1, 4,\n",
      "        1, 3, 5, 5, 2, 0, 0, 7])\n",
      "tensor([5, 8, 2, 8, 1, 9, 1, 0, 9, 1, 9, 3, 1, 5, 4, 2, 1, 4, 4, 1, 4, 3, 9, 4,\n",
      "        9, 6, 8, 1, 8, 2, 3, 1])\n",
      "tensor([1, 7, 0, 2, 5, 6, 2, 8, 9, 2, 0, 0, 6, 5, 6, 1, 5, 5, 8, 1, 3, 8, 1, 6,\n",
      "        6, 2, 1, 9, 1, 7, 5, 1])\n",
      "tensor([3, 1, 1, 7, 5, 6, 4, 3, 2, 3, 2, 6, 0, 9, 5, 2, 7, 1, 5, 3, 2, 6, 7, 0,\n",
      "        3, 6, 3, 4, 4, 0, 8, 7])\n",
      "tensor([3, 4, 1, 9, 8, 3, 3, 8, 6, 8, 0, 7, 8, 4, 9, 6, 8, 1, 1, 4, 6, 0, 2, 1,\n",
      "        7, 2, 5, 7, 0, 9, 3, 4])\n",
      "tensor([2, 1, 7, 6, 1, 7, 2, 6, 9, 9, 0, 1, 8, 6, 8, 1, 2, 1, 0, 1, 7, 1, 4, 4,\n",
      "        2, 6, 2, 6, 7, 7, 5, 8])\n",
      "tensor([3, 7, 0, 0, 3, 5, 8, 0, 2, 8, 4, 1, 3, 2, 1, 1, 8, 9, 4, 3, 1, 2, 4, 9,\n",
      "        7, 1, 1, 4, 8, 0, 9, 7])\n",
      "tensor([1, 9, 8, 1, 2, 3, 1, 0, 9, 9, 5, 9, 9, 7, 8, 3, 3, 3, 0, 7, 6, 8, 2, 2,\n",
      "        6, 3, 7, 4, 7, 7, 5, 2])\n",
      "tensor([6, 9, 5, 7, 1, 1, 6, 6, 5, 1, 7, 1, 4, 2, 1, 5, 2, 8, 4, 7, 4, 1, 3, 6,\n",
      "        7, 7, 5, 7, 4, 7, 9, 1])\n",
      "tensor([6, 4, 7, 2, 7, 6, 0, 0, 5, 7, 1, 8, 0, 0, 3, 8, 1, 7, 1, 5, 1, 6, 6, 3,\n",
      "        5, 5, 9, 8, 6, 4, 3, 2])\n",
      "tensor([9, 2, 3, 1, 5, 2, 3, 1, 3, 3, 2, 4, 8, 5, 5, 4, 5, 9, 4, 7, 8, 8, 9, 4,\n",
      "        8, 9, 0, 5, 0, 6, 3, 6])\n",
      "tensor([3, 6, 9, 4, 1, 1, 5, 2, 7, 4, 3, 2, 2, 8, 5, 2, 9, 7, 7, 9, 3, 8, 6, 6,\n",
      "        9, 0, 2, 0, 3, 3, 0, 8])\n",
      "tensor([2, 9, 0, 5, 4, 6, 0, 6, 7, 8, 9, 1, 3, 4, 3, 7, 9, 7, 1, 3, 6, 1, 9, 2,\n",
      "        6, 0, 3, 6, 3, 0, 9, 0])\n",
      "tensor([8, 1, 5, 5, 1, 6, 4, 3, 7, 9, 5, 1, 1, 3, 4, 9, 1, 0, 2, 4, 3, 6, 7, 3,\n",
      "        9, 5, 0, 7, 3, 4, 0, 3])\n",
      "tensor([5, 5, 0, 0, 1, 8, 3, 5, 6, 7, 5, 5, 0, 6, 3, 1, 3, 2, 1, 2, 8, 2, 1, 8,\n",
      "        0, 3, 7, 4, 7, 3, 7, 4])\n",
      "tensor([0, 1, 1, 6, 8, 5, 9, 6, 1, 0, 2, 9, 0, 0, 0, 4, 2, 4, 6, 8, 9, 8, 5, 2,\n",
      "        2, 0, 8, 7, 5, 5, 0, 9])\n",
      "tensor([2, 9, 5, 1, 8, 5, 6, 1, 3, 9, 3, 6, 5, 2, 0, 2, 1, 4, 5, 6, 4, 7, 7, 9,\n",
      "        3, 6, 7, 6, 1, 4, 1, 7])\n",
      "tensor([5, 5, 7, 7, 4, 2, 9, 8, 7, 1, 0, 6, 3, 7, 9, 9, 1, 7, 2, 6, 6, 9, 2, 8,\n",
      "        0, 0, 8, 5, 9, 2, 8, 4])\n",
      "tensor([1, 7, 5, 1, 2, 6, 4, 9, 5, 9, 2, 8, 8, 5, 0, 1, 9, 2, 1, 2, 6, 1, 0, 8,\n",
      "        3, 4, 6, 2, 4, 2, 8, 5])\n",
      "tensor([1, 9, 5, 3, 4, 6, 6, 4, 4, 7, 5, 1, 0, 8, 8, 2, 6, 3, 3, 2, 8, 5, 6, 6,\n",
      "        1, 1, 8, 8, 7, 4, 7, 9])\n",
      "tensor([4, 6, 2, 0, 3, 2, 4, 2, 9, 0, 9, 5, 6, 0, 4, 4, 9, 0, 9, 6, 0, 4, 1, 0,\n",
      "        3, 0, 5, 5, 3, 0, 9, 5])\n",
      "tensor([3, 2, 9, 9, 4, 0, 0, 0, 6, 0, 2, 8, 2, 7, 9, 2, 0, 8, 7, 3, 5, 1, 4, 7,\n",
      "        0, 3, 2, 6, 6, 6, 6, 8])\n",
      "tensor([1, 7, 8, 7, 7, 0, 1, 2, 1, 9, 1, 7, 8, 1, 7, 9, 9, 5, 5, 6, 5, 7, 6, 6,\n",
      "        7, 9, 9, 1, 5, 6, 0, 1])\n",
      "tensor([5, 9, 5, 1, 5, 2, 4, 5, 2, 5, 9, 6, 4, 2, 0, 2, 4, 2, 1, 1, 6, 2, 7, 5,\n",
      "        6, 1, 4, 7, 7, 6, 2, 0])\n",
      "tensor([6, 8, 9, 8, 6, 1, 1, 3, 7, 0, 2, 0, 5, 4, 6, 5, 0, 4, 0, 5, 4, 7, 4, 1,\n",
      "        1, 5, 4, 3, 5, 5, 5, 6])\n",
      "tensor([4, 8, 6, 1, 3, 0, 4, 3, 4, 7, 6, 5, 3, 7, 2, 1, 7, 2, 9, 9, 0, 1, 3, 2,\n",
      "        4, 3, 6, 2, 5, 5, 7, 9])\n",
      "tensor([5, 6, 2, 1, 8, 8, 9, 3, 9, 5, 2, 5, 8, 0, 3, 6, 6, 5, 0, 0, 9, 2, 9, 6,\n",
      "        8, 2, 6, 9, 1, 6, 8, 1])\n",
      "tensor([5, 4, 6, 8, 5, 6, 0, 4, 1, 8, 4, 3, 1, 1, 9, 2, 1, 3, 2, 0, 7, 4, 1, 6,\n",
      "        1, 0, 1, 6, 7, 2, 3, 1])\n",
      "tensor([1, 6, 6, 9, 4, 5, 9, 1, 5, 1, 9, 5, 5, 5, 3, 5, 3, 6, 9, 6, 4, 3, 4, 3,\n",
      "        0, 5, 9, 8, 9, 6, 5, 2])\n",
      "tensor([2, 1, 7, 3, 4, 0, 7, 2, 4, 8, 8, 6, 3, 6, 1, 8, 1, 4, 0, 2, 3, 2, 1, 5,\n",
      "        7, 7, 4, 7, 4, 0, 0, 8])\n",
      "tensor([1, 1, 7, 4, 3, 6, 1, 0, 9, 9, 5, 0, 2, 7, 9, 5, 8, 7, 6, 5, 7, 1, 6, 4,\n",
      "        3, 5, 5, 5, 9, 3, 0, 6])\n",
      "tensor([2, 3, 1, 2, 4, 2, 5, 1, 0, 2, 6, 7, 0, 9, 1, 5, 3, 0, 3, 6, 0, 8, 7, 6,\n",
      "        9, 2, 9, 2, 1, 8, 4, 7])\n",
      "tensor([4, 3, 8, 0, 5, 3, 0, 2, 6, 1, 0, 6, 9, 8, 4, 1, 4, 8, 4, 8, 6, 9, 7, 8,\n",
      "        8, 9, 1, 0, 1, 9, 3, 3])\n",
      "tensor([1, 0, 8, 3, 1, 0, 3, 0, 8, 6, 2, 2, 3, 4, 7, 0, 4, 8, 9, 3, 8, 8, 0, 8,\n",
      "        9, 3, 9, 5, 3, 1, 0, 2])\n",
      "tensor([2, 5, 9, 2, 6, 2, 0, 9, 3, 1, 0, 9, 3, 5, 4, 1, 4, 6, 7, 9, 5, 6, 0, 8,\n",
      "        1, 4, 3, 2, 9, 8, 3, 1])\n",
      "tensor([1, 1, 1, 0, 7, 9, 8, 4, 4, 6, 9, 5, 8, 5, 2, 1, 9, 9, 8, 8, 5, 0, 6, 1,\n",
      "        0, 0, 5, 9, 2, 3, 7, 7])\n",
      "tensor([6, 0, 3, 3, 1, 5, 9, 3, 8, 2, 5, 7, 7, 3, 3, 0, 5, 9, 4, 9, 8, 5, 2, 0,\n",
      "        1, 5, 0, 6, 0, 9, 4, 6])\n",
      "tensor([1, 6, 0, 9, 6, 5, 3, 0, 9, 4, 8, 7, 4, 6, 4, 1, 2, 1, 5, 2, 8, 5, 7, 8,\n",
      "        1, 3, 6, 4, 6, 7, 1, 0])\n",
      "tensor([7, 6, 8, 0, 4, 8, 1, 8, 7, 9, 0, 5, 9, 7, 4, 8, 8, 2, 4, 6, 7, 8, 0, 0,\n",
      "        5, 1, 6, 6, 7, 6, 3, 3])\n",
      "tensor([6, 1, 9, 6, 3, 7, 5, 9, 7, 1, 7, 8, 1, 7, 9, 2, 5, 6, 7, 3, 5, 1, 0, 5,\n",
      "        9, 6, 6, 6, 1, 3, 3, 3])\n",
      "tensor([6, 0, 9, 3, 2, 9, 1, 4, 6, 8, 5, 0, 8, 7, 0, 7, 3, 6, 3, 1, 0, 3, 4, 4,\n",
      "        5, 4, 0, 7, 5, 1, 8, 2])\n",
      "tensor([5, 5, 6, 1, 7, 8, 7, 2, 3, 6, 7, 3, 0, 2, 5, 7, 4, 2, 4, 8, 5, 6, 2, 0,\n",
      "        0, 1, 5, 7, 1, 9, 6, 7])\n",
      "tensor([3, 2, 2, 6, 0, 8, 8, 9, 5, 8, 0, 1, 2, 2, 7, 4, 2, 9, 3, 9, 3, 2, 6, 7,\n",
      "        5, 1, 6, 2, 7, 6, 2, 2])\n",
      "tensor([4, 5, 3, 4, 1, 3, 0, 0, 6, 7, 7, 3, 9, 3, 9, 8, 2, 3, 3, 6, 9, 4, 9, 8,\n",
      "        9, 2, 8, 1, 8, 8, 9, 3])\n",
      "tensor([9, 1, 3, 4, 8, 7, 1, 3, 6, 7, 0, 5, 7, 1, 7, 9, 4, 2, 3, 5, 1, 2, 1, 7,\n",
      "        3, 7, 1, 1, 3, 4, 3, 6])\n",
      "tensor([3, 9, 2, 4, 1, 6, 4, 7, 7, 0, 2, 5, 4, 8, 5, 1, 1, 9, 7, 6, 1, 2, 5, 2,\n",
      "        8, 8, 1, 6, 1, 7, 3, 3])\n",
      "tensor([8, 8, 5, 7, 4, 6, 9, 9, 3, 3, 4, 9, 1, 3, 4, 2, 8, 8, 4, 7, 1, 1, 1, 2,\n",
      "        2, 9, 3, 4, 4, 6, 2, 2])\n",
      "tensor([3, 1, 6, 1, 8, 0, 6, 3, 2, 7, 6, 6, 4, 8, 5, 0, 9, 0, 7, 2, 2, 7, 8, 7,\n",
      "        6, 0, 2, 7, 9, 7, 5, 4])\n",
      "tensor([0, 0, 0, 7, 2, 6, 9, 7, 3, 5, 1, 0, 6, 5, 4, 2, 1, 3, 0, 0, 0, 7, 4, 3,\n",
      "        7, 2, 2, 1, 4, 8, 6, 2])\n",
      "tensor([0, 2, 1, 9, 2, 3, 0, 1, 9, 7, 1, 8, 2, 1, 6, 1, 0, 6, 0, 0, 9, 2, 4, 0,\n",
      "        2, 7, 4, 1, 5, 0, 2, 4])\n",
      "tensor([1, 3, 8, 8, 9, 9, 8, 6, 0, 5, 8, 9, 3, 9, 1, 0, 0, 8, 1, 4, 9, 8, 0, 0,\n",
      "        5, 4, 9, 6, 1, 0, 7, 2])\n",
      "tensor([2, 6, 2, 6, 1, 5, 5, 2, 6, 0, 8, 8, 2, 4, 2, 2, 7, 8, 2, 3, 1, 3, 4, 1,\n",
      "        4, 1, 4, 0, 1, 9, 8, 3])\n",
      "tensor([2, 2, 7, 5, 1, 1, 8, 3, 6, 3, 2, 3, 3, 0, 9, 4, 7, 2, 5, 4, 8, 5, 0, 7,\n",
      "        1, 6, 6, 9, 7, 7, 7, 6])\n",
      "tensor([3, 9, 9, 9, 0, 4, 8, 5, 0, 8, 4, 1, 8, 4, 8, 9, 7, 8, 7, 0, 5, 9, 7, 7,\n",
      "        3, 6, 5, 1, 9, 6, 4, 3])\n",
      "tensor([5, 7, 7, 3, 2, 6, 5, 8, 1, 6, 9, 2, 6, 1, 0, 9, 5, 3, 6, 0, 0, 0, 8, 1,\n",
      "        8, 3, 9, 0, 4, 4, 0, 7])\n",
      "tensor([5, 2, 7, 2, 5, 7, 4, 5, 2, 5, 3, 6, 3, 2, 5, 0, 5, 5, 8, 3, 5, 3, 0, 4,\n",
      "        0, 2, 1, 2, 8, 9, 1, 9])\n",
      "tensor([9, 2, 1, 3, 5, 3, 1, 1, 3, 2, 2, 8, 1, 2, 3, 7, 5, 2, 1, 4, 9, 8, 6, 1,\n",
      "        4, 8, 1, 3, 3, 3, 0, 2])\n",
      "tensor([9, 8, 6, 3, 7, 6, 1, 0, 8, 2, 1, 8, 4, 6, 5, 4, 7, 7, 3, 5, 7, 0, 8, 6,\n",
      "        9, 9, 7, 7, 6, 7, 6, 8])\n",
      "tensor([7, 7, 5, 8, 3, 6, 4, 1, 5, 7, 5, 9, 6, 9, 1, 6, 9, 9, 1, 8, 9, 9, 4, 0,\n",
      "        2, 7, 0, 2, 1, 7, 8, 3])\n",
      "tensor([7, 0, 8, 2, 7, 4, 9, 9, 3, 9, 0, 2, 5, 4, 1, 0, 1, 6, 8, 7, 7, 4, 8, 3,\n",
      "        9, 0, 7, 0, 4, 0, 4, 6])\n",
      "tensor([3, 3, 1, 6, 3, 4, 9, 2, 1, 7, 0, 6, 8, 0, 6, 4, 7, 4, 0, 0, 7, 9, 4, 8,\n",
      "        7, 4, 9, 8, 2, 3, 8, 2])\n",
      "tensor([9, 9, 0, 2, 1, 5, 4, 2, 2, 6, 8, 8, 6, 9, 3, 7, 4, 4, 2, 5, 6, 0, 5, 8,\n",
      "        1, 2, 4, 8, 8, 7, 2, 1])\n",
      "tensor([4, 0, 7, 3, 2, 0, 5, 7, 2, 6, 0, 7, 0, 5, 2, 6, 7, 6, 9, 7, 4, 2, 6, 5,\n",
      "        9, 9, 8, 6, 5, 6, 7, 1])\n",
      "tensor([3, 8, 4, 5, 4, 9, 6, 6, 0, 8, 3, 0, 2, 9, 3, 1, 5, 4, 4, 9, 8, 9, 6, 8,\n",
      "        3, 2, 4, 5, 6, 5, 5, 8])\n",
      "tensor([8, 7, 1, 9, 8, 7, 0, 9, 8, 0, 1, 4, 3, 1, 6, 1, 8, 0, 0, 6, 3, 5, 2, 0,\n",
      "        5, 6, 3, 2, 8, 4, 6, 7])\n",
      "tensor([2, 2, 2, 6, 0, 9, 9, 8, 5, 4, 3, 9, 0, 9, 8, 7, 9, 4, 8, 0, 9, 6, 8, 7,\n",
      "        5, 1, 1, 6, 1, 5, 5, 6])\n",
      "tensor([8, 4, 4, 8, 5, 1, 7, 5, 8, 1, 4, 3, 9, 8, 8, 6, 0, 7, 6, 3, 5, 3, 8, 8,\n",
      "        8, 0, 3, 7, 3, 4, 3, 8])\n",
      "tensor([9, 4, 2, 4, 3, 4, 9, 7, 6, 8, 7, 0, 3, 9, 5, 0, 2, 0, 9, 6, 1, 9, 0, 0,\n",
      "        1, 9, 9, 1, 0, 0, 0, 4])\n",
      "tensor([4, 0, 4, 7, 2, 9, 5, 2, 2, 7, 1, 1, 2, 7, 9, 6, 3, 5, 5, 0, 1, 9, 8, 1,\n",
      "        6, 2, 8, 8, 3, 0, 1, 1])\n",
      "tensor([1, 6, 8, 5, 0, 3, 0, 0, 6, 8, 5, 3, 3, 2, 1, 3, 4, 3, 1, 7, 0, 4, 8, 9,\n",
      "        4, 2, 0, 2, 9, 6, 4, 9])\n",
      "tensor([8, 2, 7, 2, 3, 3, 5, 0, 6, 0, 0, 2, 2, 6, 2, 3, 8, 5, 9, 2, 8, 3, 5, 8,\n",
      "        2, 5, 6, 8, 6, 7, 0, 3])\n",
      "tensor([1, 1, 0, 1, 2, 9, 6, 0, 8, 4, 6, 6, 4, 9, 2, 3, 4, 9, 7, 4, 3, 3, 1, 7,\n",
      "        8, 3, 0, 3, 1, 5, 1, 6])\n",
      "tensor([4, 1, 8, 2, 4, 1, 3, 5, 9, 0, 6, 2, 0, 8, 4, 5, 7, 6, 4, 4, 8, 9, 6, 1,\n",
      "        1, 3, 9, 7, 4, 4, 6, 1])\n",
      "tensor([5, 7, 7, 5, 4, 2, 4, 9, 0, 3, 3, 0, 2, 0, 5, 7, 2, 1, 4, 5, 2, 7, 4, 0,\n",
      "        0, 5, 7, 0, 3, 3, 1, 3])\n",
      "tensor([9, 4, 0, 1, 3, 3, 2, 5, 7, 7, 3, 1, 3, 2, 7, 0, 1, 8, 7, 1, 4, 3, 1, 8,\n",
      "        6, 8, 9, 5, 8, 7, 4, 9])\n",
      "tensor([0, 4, 1, 3, 9, 3, 8, 6, 9, 5, 0, 9, 8, 1, 1, 8, 3, 4, 4, 9, 8, 5, 2, 9,\n",
      "        0, 8, 5, 3, 9, 1, 9, 2])\n",
      "tensor([0, 2, 3, 8, 2, 1, 8, 9, 2, 9, 5, 0, 6, 1, 0, 7, 9, 5, 3, 3, 0, 0, 1, 6,\n",
      "        4, 9, 7, 2, 0, 3, 3, 8])\n",
      "tensor([3, 5, 5, 4, 5, 2, 8, 4, 5, 7, 1, 9, 1, 7, 4, 8, 1, 1, 9, 8, 4, 6, 2, 0,\n",
      "        3, 3, 7, 5, 7, 7, 3, 2])\n",
      "tensor([0, 8, 1, 7, 5, 4, 1, 5, 5, 1, 8, 5, 7, 3, 3, 3, 3, 1, 3, 1, 0, 7, 5, 0,\n",
      "        6, 1, 5, 4, 2, 8, 1, 5])\n",
      "tensor([8, 4, 9, 5, 7, 1, 8, 6, 4, 1, 4, 0, 3, 0, 2, 4, 1, 5, 9, 4, 1, 2, 7, 9,\n",
      "        0, 4, 9, 1, 7, 4, 2, 9])\n",
      "tensor([5, 3, 3, 3, 5, 1, 1, 0, 0, 2, 4, 2, 9, 3, 2, 8, 6, 7, 3, 4, 7, 4, 9, 0,\n",
      "        4, 0, 9, 1, 8, 8, 5, 4])\n",
      "tensor([3, 4, 1, 6, 9, 5, 9, 1, 3, 7, 9, 2, 3, 9, 6, 3, 4, 3, 0, 3, 3, 6, 9, 9,\n",
      "        4, 5, 6, 5, 6, 5, 1, 8])\n",
      "tensor([2, 0, 1, 8, 2, 5, 2, 2, 5, 6, 3, 1, 0, 8, 1, 1, 3, 9, 6, 7, 4, 7, 1, 8,\n",
      "        5, 4, 3, 0, 4, 9, 9, 4])\n",
      "tensor([1, 2, 2, 2, 1, 2, 1, 3, 3, 3, 4, 3, 2, 3, 7, 7, 0, 1, 3, 2, 7, 6, 3, 6,\n",
      "        7, 7, 2, 7, 3, 4, 7, 8])\n",
      "tensor([3, 5, 5, 0, 0, 8, 8, 5, 0, 3, 9, 2, 1, 2, 8, 9, 1, 2, 1, 8, 7, 4, 6, 3,\n",
      "        4, 1, 2, 9, 8, 3, 1, 6])\n",
      "tensor([2, 5, 2, 6, 0, 2, 7, 6, 8, 6, 3, 7, 8, 2, 4, 1, 6, 7, 6, 6, 3, 8, 2, 6,\n",
      "        1, 8, 5, 6, 0, 9, 6, 0])\n",
      "tensor([3, 5, 9, 6, 8, 7, 9, 0, 9, 8, 0, 5, 3, 9, 5, 0, 9, 8, 5, 1, 5, 7, 9, 0,\n",
      "        9, 1, 1, 2, 9, 4, 1, 2])\n",
      "tensor([1, 3, 6, 9, 3, 5, 4, 0, 0, 9, 4, 7, 9, 1, 3, 7, 6, 3, 4, 9, 4, 2, 4, 1,\n",
      "        5, 4, 3, 3, 9, 8, 9, 7])\n",
      "tensor([6, 2, 0, 1, 2, 1, 0, 1, 7, 1, 2, 6, 0, 9, 1, 7, 7, 9, 8, 6, 9, 4, 4, 1,\n",
      "        0, 0, 6, 9, 8, 6, 4, 1])\n",
      "tensor([3, 0, 7, 6, 9, 0, 3, 3, 0, 5, 3, 7, 2, 6, 8, 7, 4, 5, 3, 0, 8, 7, 9, 0,\n",
      "        5, 7, 0, 8, 8, 4, 2, 3])\n",
      "tensor([0, 7, 5, 9, 9, 9, 3, 8, 1, 9, 8, 8, 8, 2, 1, 5, 7, 4, 7, 9, 8, 9, 0, 9,\n",
      "        4, 0, 2, 9, 9, 7, 1, 9])\n",
      "tensor([6, 8, 4, 8, 3, 1, 2, 2, 7, 9, 7, 2, 2, 4, 4, 3, 7, 3, 9, 9, 3, 9, 5, 3,\n",
      "        7, 4, 8, 6, 9, 3, 6, 4])\n",
      "tensor([1, 0, 7, 7, 5, 2, 6, 7, 4, 0, 4, 5, 3, 2, 5, 0, 3, 9, 3, 7, 9, 6, 8, 1,\n",
      "        5, 0, 9, 0, 3, 4, 3, 8])\n",
      "tensor([5, 2, 9, 8, 8, 3, 6, 1, 3, 4, 9, 0, 0, 4, 1, 2, 2, 6, 7, 7, 9, 3, 8, 1,\n",
      "        3, 1, 6, 9, 3, 6, 2, 2])\n",
      "tensor([4, 7, 6, 1, 9, 4, 9, 1, 9, 9, 2, 5, 6, 3, 5, 4, 7, 2, 9, 4, 1, 9, 4, 9,\n",
      "        2, 9, 1, 1, 6, 0, 4, 5])\n",
      "tensor([3, 6, 4, 4, 7, 5, 2, 4, 0, 7, 1, 7, 8, 2, 4, 1, 4, 9, 3, 7, 1, 1, 6, 4,\n",
      "        6, 5, 1, 5, 7, 2, 2, 9])\n",
      "tensor([0, 9, 1, 3, 2, 9, 1, 0, 0, 8, 9, 7, 9, 7, 1, 9, 0, 8, 9, 6, 9, 8, 1, 4,\n",
      "        3, 2, 9, 3, 4, 5, 4, 5])\n",
      "tensor([6, 4, 5, 6, 2, 2, 4, 3, 8, 7, 8, 5, 0, 0, 5, 7, 8, 1, 8, 5, 8, 6, 5, 6,\n",
      "        9, 0, 1, 1, 7, 3, 3, 9])\n",
      "tensor([5, 6, 2, 7, 2, 3, 3, 5, 3, 1, 4, 2, 1, 9, 0, 3, 1, 2, 7, 6, 7, 2, 9, 6,\n",
      "        0, 0, 2, 9, 7, 1, 8, 2])\n",
      "tensor([1, 2, 8, 7, 6, 6, 2, 2, 4, 1, 4, 7, 2, 1, 3, 5, 4, 7, 1, 9, 0, 3, 6, 2,\n",
      "        6, 9, 1, 9, 4, 4, 1, 4])\n",
      "tensor([2, 7, 8, 4, 7, 0, 0, 1, 3, 5, 6, 6, 4, 4, 0, 9, 3, 2, 9, 3, 0, 9, 6, 5,\n",
      "        3, 8, 3, 0, 2, 4, 0, 3])\n",
      "tensor([6, 6, 3, 4, 5, 0, 8, 5, 4, 2, 0, 8, 4, 9, 1, 3, 2, 3, 0, 9, 3, 8, 9, 2,\n",
      "        8, 3, 1, 0, 6, 7, 4, 5])\n",
      "tensor([6, 5, 4, 5, 7, 2, 3, 0, 7, 2, 6, 4, 0, 4, 9, 4, 2, 4, 2, 7, 7, 0, 2, 2,\n",
      "        5, 1, 6, 4, 8, 7, 5, 8])\n",
      "tensor([1, 3, 6, 9, 1, 6, 5, 5, 2, 1, 5, 4, 7, 8, 5, 7, 9, 1, 4, 0, 8, 7, 7, 2,\n",
      "        9, 7, 0, 4, 2, 8, 9, 7])\n",
      "tensor([5, 3, 9, 7, 4, 6, 0, 5, 2, 8, 5, 5, 8, 2, 8, 9, 8, 2, 5, 8, 7, 0, 4, 0,\n",
      "        1, 0, 3, 1, 2, 0, 6, 4])\n",
      "tensor([7, 9, 0, 0, 0, 4, 4, 8, 1, 2, 5, 7, 5, 2, 6, 0, 0, 4, 4, 0, 3, 9, 2, 5,\n",
      "        7, 6, 2, 8, 4, 1, 6, 7])\n",
      "tensor([0, 2, 8, 3, 9, 2, 0, 6, 9, 2, 0, 4, 1, 9, 8, 8, 1, 8, 3, 4, 2, 0, 3, 8,\n",
      "        3, 2, 6, 9, 2, 8, 3, 4])\n",
      "tensor([4, 6, 2, 4, 8, 0, 6, 3, 5, 0, 1, 3, 1, 2, 7, 3, 7, 4, 1, 5, 1, 8, 4, 0,\n",
      "        0, 0, 8, 6, 5, 3, 1, 8])\n",
      "tensor([6, 7, 9, 5, 0, 8, 8, 1, 1, 3, 6, 5, 1, 3, 1, 7, 8, 7, 3, 8, 4, 1, 0, 9,\n",
      "        2, 9, 6, 3, 1, 2, 0, 2])\n",
      "tensor([1, 4, 9, 5, 7, 0, 4, 0, 8, 2, 0, 5, 8, 4, 6, 3, 6, 4, 4, 3, 8, 0, 6, 0,\n",
      "        9, 0, 4, 7, 8, 9, 5, 5])\n",
      "tensor([2, 8, 6, 7, 6, 2, 9, 7, 4, 2, 3, 9, 0, 8, 9, 2, 6, 7, 4, 0, 7, 7, 1, 2,\n",
      "        1, 0, 9, 5, 9, 7, 2, 6])\n",
      "tensor([2, 9, 6, 8, 2, 9, 0, 9, 0, 3, 9, 1, 4, 7, 3, 4, 9, 5, 9, 9, 3, 4, 8, 5,\n",
      "        1, 7, 6, 1, 5, 4, 2, 7])\n",
      "tensor([0, 7, 9, 9, 1, 3, 2, 0, 9, 4, 6, 7, 9, 4, 6, 7, 6, 2, 5, 1, 8, 6, 3, 3,\n",
      "        3, 8, 0, 8, 6, 7, 1, 4])\n",
      "tensor([1, 4, 9, 0, 8, 1, 0, 4, 2, 1, 2, 3, 9, 6, 7, 1, 7, 5, 6, 9, 6, 5, 9, 4,\n",
      "        4, 1, 2, 3, 6, 2, 9, 5])\n",
      "tensor([2, 0, 0, 9, 4, 4, 8, 0, 2, 1, 7, 0, 1, 8, 6, 5, 5, 5, 3, 3, 6, 5, 5, 6,\n",
      "        9, 8, 5, 2, 6, 7, 9, 6])\n",
      "tensor([6, 4, 9, 2, 8, 4, 8, 6, 0, 5, 1, 5, 7, 9, 1, 7, 5, 8, 7, 2, 3, 9, 3, 2,\n",
      "        1, 7, 4, 2, 8, 4, 4, 4])\n",
      "tensor([1, 9, 2, 4, 9, 8, 4, 2, 6, 7, 6, 8, 3, 4, 5, 2, 6, 1, 1, 3, 6, 4, 7, 0,\n",
      "        9, 2, 9, 2, 0, 4, 1, 1])\n",
      "tensor([5, 9, 2, 5, 7, 4, 1, 3, 7, 4, 3, 3, 3, 1, 5, 7, 9, 1, 3, 6, 2, 9, 6, 3,\n",
      "        0, 0, 1, 2, 2, 1, 3, 4])\n",
      "tensor([9, 4, 1, 3, 2, 1, 1, 2, 0, 1, 7, 0, 7, 2, 4, 9, 6, 8, 2, 8, 7, 5, 3, 1,\n",
      "        4, 8, 7, 2, 1, 9, 1, 0])\n",
      "tensor([3, 1, 1, 7, 3, 9, 9, 4, 9, 7, 1, 6, 2, 3, 8, 8, 4, 2, 1, 2, 8, 7, 9, 8,\n",
      "        2, 6, 4, 3, 7, 6, 7, 8])\n",
      "tensor([0, 6, 2, 2, 0, 2, 6, 2, 4, 3, 9, 9, 0, 3, 0, 0, 3, 0, 9, 8, 3, 2, 8, 2,\n",
      "        3, 4, 3, 8, 0, 9, 5, 4])\n",
      "tensor([5, 0, 3, 5, 3, 0, 4, 5, 8, 2, 4, 6, 7, 6, 3, 6, 2, 5, 9, 1, 6, 3, 6, 1,\n",
      "        2, 3, 2, 0, 6, 3, 7, 6])\n",
      "tensor([9, 6, 7, 7, 8, 0, 9, 8, 4, 2, 9, 5, 1, 8, 1, 5, 9, 8, 9, 1, 3, 7, 5, 6,\n",
      "        3, 7, 1, 0, 4, 1, 7, 6])\n",
      "tensor([5, 9, 4, 6, 0, 4, 3, 4, 9, 4, 4, 3, 4, 7, 7, 1, 3, 2, 4, 9, 0, 6, 6, 7,\n",
      "        0, 9, 2, 4, 2, 6, 8, 2])\n",
      "tensor([2, 8, 2, 5, 8, 8, 6, 0, 0, 8, 5, 0, 6, 1, 0, 1, 6, 2, 1, 3, 4, 4, 6, 6,\n",
      "        2, 9, 5, 1, 4, 2, 4, 0])\n",
      "tensor([1, 1, 9, 2, 0, 0, 0, 0, 2, 7, 2, 0, 4, 6, 9, 5, 9, 9, 0, 6, 7, 3, 3, 1,\n",
      "        1, 9, 2, 5, 5, 0, 7, 3])\n",
      "tensor([7, 0, 6, 1, 1, 6, 0, 6, 8, 7, 1, 5, 8, 7, 1, 1, 2, 4, 1, 9, 8, 1, 6, 7,\n",
      "        3, 4, 3, 4, 5, 2, 0, 6])\n",
      "tensor([3, 0, 4, 6, 2, 1, 4, 4, 0, 0, 4, 4, 1, 6, 1, 5, 9, 0, 5, 1, 8, 9, 2, 4,\n",
      "        4, 8, 5, 1, 5, 7, 7, 6])\n",
      "tensor([4, 4, 1, 7, 5, 7, 8, 9, 4, 3, 0, 9, 1, 4, 8, 6, 2, 2, 2, 2, 3, 8, 4, 0,\n",
      "        2, 9, 7, 7, 4, 5, 3, 6])\n",
      "tensor([1, 1, 7, 9, 9, 3, 5, 1, 1, 6, 0, 1, 8, 8, 7, 9, 5, 9, 1, 3, 2, 7, 3, 3,\n",
      "        1, 0, 3, 0, 2, 4, 9, 2])\n",
      "tensor([8, 6, 9, 8, 5, 6, 4, 6, 1, 0, 1, 2, 0, 3, 5, 5, 0, 0, 3, 4, 4, 3, 4, 2,\n",
      "        5, 2, 5, 0, 4, 1, 4, 9])\n",
      "tensor([5, 2, 3, 1, 3, 4, 1, 5, 3, 2, 4, 2, 9, 1, 2, 4, 6, 3, 7, 6, 8, 9, 9, 8,\n",
      "        0, 7, 2, 8, 8, 6, 0, 8])\n",
      "tensor([1, 2, 2, 0, 9, 4, 2, 7, 8, 3, 7, 4, 3, 8, 9, 8, 4, 0, 4, 0, 2, 3, 3, 1,\n",
      "        4, 2, 0, 8, 8, 6, 4, 4])\n",
      "tensor([9, 0, 7, 9, 8, 1, 2, 0, 8, 3, 2, 3, 3, 9, 8, 0, 4, 8, 7, 7, 1, 0, 1, 8,\n",
      "        0, 0, 0, 8, 0, 1, 1, 5])\n",
      "tensor([1, 7, 5, 4, 3, 1, 8, 0, 8, 0, 1, 5, 5, 3, 3, 1, 2, 1, 6, 2, 4, 9, 5, 5,\n",
      "        9, 5, 0, 7, 3, 4, 1, 3])\n",
      "tensor([1, 1, 9, 9, 0, 4, 6, 6, 3, 7, 5, 6, 1, 6, 9, 8, 1, 8, 2, 5, 9, 0, 2, 9,\n",
      "        7, 9, 5, 4, 7, 1, 0, 2])\n",
      "tensor([0, 8, 0, 6, 5, 5, 2, 7, 3, 8, 8, 5, 8, 3, 2, 3, 1, 2, 7, 2, 3, 8, 9, 3,\n",
      "        3, 1, 0, 4, 5, 3, 4, 6])\n",
      "tensor([9, 4, 7, 4, 5, 2, 1, 0, 8, 8, 3, 8, 8, 5, 0, 5, 5, 3, 0, 6, 6, 6, 2, 0,\n",
      "        2, 6, 3, 2, 1, 3, 7, 1])\n",
      "tensor([5, 0, 6, 1, 3, 6, 4, 9, 0, 3, 1, 2, 8, 1, 0, 0, 2, 5, 6, 8, 0, 8, 7, 4,\n",
      "        4, 2, 1, 9, 8, 9, 9, 1])\n",
      "tensor([4, 5, 7, 1, 6, 6, 8, 6, 7, 8, 8, 3, 3, 9, 3, 2, 7, 5, 9, 7, 5, 1, 1, 0,\n",
      "        3, 8, 6, 5, 6, 6, 3, 4])\n",
      "tensor([7, 4, 9, 2, 3, 8, 6, 9, 7, 7, 4, 4, 9, 0, 1, 1, 8, 9, 0, 8, 3, 6, 8, 9,\n",
      "        0, 7, 6, 8, 2, 7, 9, 0])\n",
      "tensor([4, 0, 4, 9, 8, 9, 1, 0, 9, 2, 6, 6, 7, 1, 4, 7, 6, 3, 4, 5, 4, 8, 1, 7,\n",
      "        3, 8, 6, 3, 1, 0, 2, 8])\n",
      "tensor([2, 3, 0, 7, 2, 8, 1, 1, 3, 6, 8, 3, 0, 9, 1, 3, 9, 6, 9, 3, 2, 7, 1, 1,\n",
      "        5, 7, 8, 8, 5, 3, 4, 6])\n",
      "tensor([7, 9, 9, 7, 6, 5, 1, 9, 8, 4, 1, 2, 5, 1, 0, 1, 8, 6, 0, 9, 1, 0, 2, 3,\n",
      "        6, 5, 3, 0, 4, 7, 2, 1])\n",
      "tensor([4, 5, 4, 9, 1, 6, 1, 3, 7, 0, 7, 7, 4, 6, 5, 1, 6, 0, 4, 8, 6, 6, 7, 2,\n",
      "        9, 2, 2, 4, 3, 2, 8, 0])\n",
      "tensor([9, 0, 2, 2, 8, 5, 3, 6, 1, 4, 1, 1, 4, 0, 8, 5, 2, 2, 2, 3, 3, 2, 4, 3,\n",
      "        8, 7, 8, 4, 5, 3, 6, 8])\n",
      "tensor([6, 2, 2, 1, 3, 6, 9, 8, 7, 3, 9, 1, 9, 6, 9, 0, 0, 5, 5, 6, 7, 1, 4, 2,\n",
      "        6, 7, 3, 2, 5, 7, 8, 7])\n",
      "tensor([3, 0, 8, 3, 7, 7, 0, 8, 3, 6, 5, 2, 3, 3, 7, 6, 4, 1, 1, 4, 5, 7, 9, 2,\n",
      "        7, 6, 2, 1, 3, 6, 6, 7])\n",
      "tensor([7, 0, 7, 5, 2, 3, 4, 8, 8, 0, 4, 5, 6, 6, 2, 4, 9, 1, 4, 2, 5, 1, 3, 0,\n",
      "        7, 6, 5, 0, 4, 8, 3, 8])\n",
      "tensor([8, 2, 4, 0, 3, 2, 8, 3, 1, 5, 1, 7, 0, 9, 6, 9, 4, 9, 4, 4, 6, 9, 3, 7,\n",
      "        3, 7, 4, 0, 3, 7, 7, 7])\n",
      "tensor([9, 8, 8, 2, 3, 2, 1, 0, 6, 0, 1, 6, 3, 2, 8, 0, 7, 1, 0, 1, 6, 2, 3, 7,\n",
      "        3, 4, 9, 4, 1, 4, 0, 1])\n",
      "tensor([0, 8, 8, 8, 6, 6, 4, 7, 1, 0, 4, 1, 7, 8, 8, 4, 3, 4, 7, 0, 2, 8, 7, 9,\n",
      "        2, 1, 0, 5, 8, 8, 3, 3])\n",
      "tensor([6, 0, 8, 9, 0, 4, 3, 2, 1, 3, 3, 0, 1, 8, 7, 2, 6, 2, 7, 6, 4, 4, 2, 2,\n",
      "        9, 7, 1, 5, 2, 9, 5, 7])\n",
      "tensor([4, 8, 4, 0, 9, 8, 4, 8, 9, 7, 1, 0, 1, 2, 6, 5, 8, 0, 5, 5, 8, 4, 8, 4,\n",
      "        8, 8, 8, 3, 1, 3, 3, 3])\n",
      "tensor([3, 3, 8, 1, 9, 9, 7, 2, 2, 5, 1, 4, 5, 2, 6, 0, 9, 4, 4, 6, 5, 9, 1, 8,\n",
      "        8, 8, 4, 7, 2, 9, 3, 7])\n",
      "tensor([3, 5, 9, 9, 9, 1, 4, 1, 8, 1, 6, 5, 8, 5, 9, 5, 8, 4, 0, 7, 9, 7, 7, 0,\n",
      "        0, 3, 1, 2, 4, 8, 9, 5])\n",
      "tensor([8, 9, 9, 4, 6, 4, 9, 2, 7, 2, 4, 2, 5, 0, 2, 7, 3, 6, 4, 1, 0, 7, 7, 3,\n",
      "        2, 6, 1, 3, 3, 6, 6, 1])\n",
      "tensor([6, 7, 1, 5, 5, 2, 9, 9, 1, 9, 0, 9, 0, 5, 4, 3, 8, 3, 1, 7, 2, 7, 5, 6,\n",
      "        4, 9, 1, 3, 0, 5, 7, 2])\n",
      "tensor([3, 4, 5, 5, 0, 7, 3, 9, 8, 1, 6, 5, 1, 7, 1, 6, 2, 9, 6, 7, 7, 1, 0, 2,\n",
      "        1, 5, 8, 6, 2, 3, 4, 9])\n",
      "tensor([0, 0, 8, 9, 4, 5, 6, 6, 2, 3, 8, 6, 8, 8, 7, 9, 4, 7, 4, 7, 8, 6, 8, 1,\n",
      "        3, 8, 8, 9, 7, 8, 1, 3])\n",
      "tensor([1, 7, 7, 7, 3, 6, 2, 1, 6, 3, 5, 3, 2, 3, 2, 2, 6, 0, 0, 5, 0, 1, 5, 4,\n",
      "        5, 2, 1, 8, 2, 0, 0, 2])\n",
      "tensor([6, 0, 1, 5, 8, 3, 6, 2, 4, 1, 1, 2, 1, 7, 7, 8, 7, 8, 5, 3, 7, 3, 9, 6,\n",
      "        4, 5, 8, 4, 3, 7, 1, 5])\n",
      "tensor([0, 2, 7, 6, 7, 6, 7, 3, 6, 3, 0, 0, 8, 2, 5, 0, 3, 6, 9, 8, 8, 7, 6, 3,\n",
      "        8, 8, 7, 8, 1, 8, 5, 4])\n",
      "tensor([5, 5, 9, 2, 7, 5, 5, 1, 3, 2, 0, 1, 4, 6, 3, 9, 5, 7, 3, 9, 6, 0, 5, 9,\n",
      "        5, 1, 8, 6, 9, 5, 2, 3])\n",
      "tensor([9, 2, 4, 7, 8, 1, 1, 1, 5, 1, 7, 3, 1, 9, 6, 6, 9, 4, 8, 1, 0, 9, 7, 2,\n",
      "        8, 1, 4, 5, 7, 0, 3, 0])\n",
      "tensor([9, 8, 0, 4, 1, 1, 7, 6, 3, 6, 9, 0, 8, 5, 1, 6, 2, 1, 1, 9, 1, 0, 4, 7,\n",
      "        6, 5, 3, 4, 2, 8, 0, 8])\n",
      "tensor([7, 7, 6, 9, 0, 6, 0, 9, 3, 3, 3, 0, 0, 0, 6, 4, 6, 0, 4, 6, 8, 1, 7, 7,\n",
      "        6, 8, 5, 8, 9, 9, 4, 0])\n",
      "tensor([2, 5, 2, 6, 8, 0, 2, 9, 6, 0, 2, 1, 3, 3, 3, 5, 6, 3, 3, 1, 6, 5, 3, 4,\n",
      "        0, 7, 7, 7, 5, 5, 6, 9])\n",
      "tensor([0, 0, 8, 7, 6, 8, 0, 0, 5, 0, 4, 9, 6, 6, 7, 3, 0, 6, 1, 1, 7, 2, 1, 5,\n",
      "        0, 2, 7, 4, 7, 6, 4, 3])\n",
      "tensor([8, 4, 0, 4, 1, 5, 3, 3, 4, 2, 3, 2, 8, 8, 9, 7, 4, 9, 4, 0, 1, 9, 6, 3,\n",
      "        4, 2, 1, 1, 6, 7, 8, 7])\n",
      "tensor([7, 8, 3, 3, 1, 3, 9, 1, 5, 7, 3, 7, 0, 1, 2, 4, 5, 1, 1, 3, 8, 4, 7, 7,\n",
      "        8, 0, 2, 5, 8, 3, 7, 1])\n",
      "tensor([0, 9, 0, 0, 0, 2, 7, 3, 6, 7, 9, 9, 7, 1, 6, 0, 7, 7, 9, 6, 1, 9, 0, 3,\n",
      "        2, 4, 7, 4, 2, 2, 5, 9])\n",
      "tensor([8, 8, 9, 8, 0, 9, 3, 4, 9, 1, 8, 6, 1, 6, 9, 7, 9, 7, 2, 9, 3, 3, 6, 0,\n",
      "        8, 4, 4, 6, 3, 1, 9, 2])\n",
      "tensor([4, 8, 7, 0, 2, 6, 5, 2, 8, 4, 0, 0, 0, 4, 6, 1, 4, 1, 5, 0, 2, 7, 1, 0,\n",
      "        1, 7, 0, 3, 5, 9, 7, 1])\n",
      "tensor([1, 5, 8, 7, 5, 6, 1, 6, 6, 9, 1, 6, 5, 9, 6, 4, 4, 6, 8, 0, 4, 6, 1, 1,\n",
      "        8, 7, 2, 0, 4, 1, 9, 5])\n",
      "tensor([1, 2, 7, 9, 0, 8, 3, 3, 9, 4, 0, 2, 4, 6, 0, 1, 7, 6, 4, 9, 4, 4, 1, 5,\n",
      "        8, 7, 3, 3, 4, 4, 6, 6])\n",
      "tensor([8, 7, 5, 4, 4, 5, 6, 9, 5, 8, 6, 8, 1, 7, 8, 1, 6, 9, 5, 3, 9, 6, 7, 8,\n",
      "        9, 2, 1, 8, 2, 4, 5, 9])\n",
      "tensor([8, 2, 2, 0, 4, 7, 2, 8, 7, 2, 6, 1, 3, 3, 6, 7, 3, 4, 5, 7, 8, 2, 1, 1,\n",
      "        1, 6, 1, 8, 1, 3, 3, 1])\n",
      "tensor([1, 7, 1, 4, 7, 4, 8, 1, 2, 3, 7, 3, 7, 4, 7, 3, 3, 3, 6, 4, 6, 5, 5, 4,\n",
      "        6, 2, 7, 8, 7, 4, 1, 8])\n",
      "tensor([2, 5, 4, 5, 3, 4, 7, 6, 1, 5, 4, 5, 9, 0, 3, 0, 3, 7, 1, 6, 5, 1, 1, 0,\n",
      "        1, 4, 7, 8, 0, 1, 2, 5])\n",
      "tensor([1, 3, 5, 5, 8, 3, 2, 8, 5, 6, 1, 2, 2, 4, 3, 3, 3, 9, 2, 5, 4, 4, 3, 6,\n",
      "        4, 7, 8, 6, 0, 6, 7, 6])\n",
      "tensor([7, 1, 1, 9, 7, 8, 3, 4, 3, 0, 1, 4, 3, 4, 6, 9, 5, 2, 8, 3, 0, 9, 8, 9,\n",
      "        1, 7, 9, 8, 9, 0, 4, 6])\n",
      "tensor([7, 1, 6, 7, 4, 9, 4, 9, 1, 7, 8, 5, 6, 4, 5, 4, 2, 7, 5, 8, 6, 3, 7, 2,\n",
      "        3, 5, 7, 3, 0, 5, 9, 4])\n",
      "tensor([8, 1, 8, 2, 3, 3, 1, 0, 0, 6, 5, 7, 1, 7, 4, 5, 6, 1, 9, 9, 7, 9, 3, 6,\n",
      "        6, 7, 9, 7, 5, 9, 9, 4])\n",
      "tensor([6, 1, 0, 5, 0, 0, 6, 7, 2, 7, 1, 2, 8, 9, 7, 9, 1, 5, 6, 9, 1, 9, 1, 3,\n",
      "        9, 4, 5, 8, 0, 1, 6, 5])\n",
      "tensor([2, 1, 4, 6, 4, 9, 9, 4, 2, 8, 1, 2, 3, 1, 0, 4, 8, 8, 1, 1, 8, 7, 4, 7,\n",
      "        0, 8, 2, 7, 4, 3, 7, 9])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [51]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      9\u001b[0m     net\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[1;32m     11\u001b[0m         images, targets, labels \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m], data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m], data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     12\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m net(images\u001b[38;5;241m.\u001b[39mto(device))\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     49\u001b[0m image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_dir, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_files[idx])\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Open image, apply transforms.\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m     54\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image, randomize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandomize)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in category_labels}\n",
    "total_pred = {classname: 0 for classname in category_labels}\n",
    "incorrect_pred = {classname: [] for classname in category_labels}\n",
    "\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    for data in test_loader:\n",
    "        images, targets, labels = data['image'], data['target'], data['label']\n",
    "        outputs = net(images.to(device))\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        print(predictions)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, target, prediction, output in zip(labels, targets, predictions, outputs):\n",
    "            # print(label, target, prediction, output)\n",
    "            if target == prediction:\n",
    "                correct_pred[label] += 1\n",
    "            else:\n",
    "                incorrect_pred[label].append(category_labels[int(prediction)])\n",
    "\n",
    "            total_pred[label] += 1\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:10s} is {accuracy:.1f} %')\n",
    "    print(f'\\tIncorrect predictions: {incorrect_pred[classname]}')\n",
    "print(f'Overall Accuracy: {(100 * float(sum(correct_pred.values()) / sum(total_pred.values()))):.3f}')\n",
    "del correct_pred\n",
    "del total_pred\n",
    "del correct_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: 0          is 19.0 %\n",
      "\tIncorrect predictions: ['3', '6', '3', '2', '2', '8', '2', '2', '2', '7', '3', '9', '3', '3', '2', '3', '7']\n",
      "Accuracy for class: 1          is 4.8 %\n",
      "\tIncorrect predictions: ['6', '2', '5', '4', '0', '0', '2', '0', '7', '7', '6', '7', '4', '7', '5', '7', '7', '6', '5', '2']\n",
      "Accuracy for class: 2          is 42.9 %\n",
      "\tIncorrect predictions: ['3', '6', '4', '3', '3', '6', '6', '6', '0', '7', '0', '8']\n",
      "Accuracy for class: 3          is 57.1 %\n",
      "\tIncorrect predictions: ['2', '9', '6', '2', '5', '9', '6', '2', '2']\n",
      "Accuracy for class: 4          is 23.8 %\n",
      "\tIncorrect predictions: ['0', '2', '0', '0', '6', '5', '6', '2', '9', '2', '7', '1', '2', '5', '8', '0']\n",
      "Accuracy for class: 5          is 19.0 %\n",
      "\tIncorrect predictions: ['6', '9', '6', '3', '3', '4', '9', '7', '2', '3', '7', '0', '6', '6', '3', '3', '8']\n",
      "Accuracy for class: 6          is 50.0 %\n",
      "\tIncorrect predictions: ['9', '8', '2', '5', '5', '3', '8', '5', '3', '5']\n",
      "Accuracy for class: 7          is 30.0 %\n",
      "\tIncorrect predictions: ['2', '2', '1', '2', '3', '6', '2', '6', '5', '2', '3', '2', '6', '2']\n",
      "Accuracy for class: 8          is 25.0 %\n",
      "\tIncorrect predictions: ['6', '7', '9', '3', '6', '6', '3', '9', '6', '9', '6', '6', '6', '3', '3']\n",
      "Accuracy for class: 9          is 10.0 %\n",
      "\tIncorrect predictions: ['7', '6', '5', '7', '4', '2', '8', '6', '1', '7', '3', '6', '3', '6', '6', '3', '1', '6']\n",
      "Overall Accuracy: 28.155\n"
     ]
    }
   ],
   "source": [
    "#Create the dataloader for training and test dat\n",
    "gui_data = CustomDataset(root_dir=os.path.join('saved_digits'),\n",
    "                         img_size=img_size,\n",
    "                         transform=transform,\n",
    "                         labels=category_labels,\n",
    "                         randomize=True)\n",
    "gui_loader = DataLoader(gui_data, batch_size=32, shuffle=True)\n",
    "\n",
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in category_labels}\n",
    "total_pred = {classname: 0 for classname in category_labels}\n",
    "incorrect_pred = {classname: [] for classname in category_labels}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    for data in gui_loader:\n",
    "        images, targets, labels = data['image'], data['target'], data['label']\n",
    "        outputs = net(images.to(device))\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "        # collect the correct predictions for each class\n",
    "        for label, target, prediction, output in zip(labels, targets, predictions, outputs):\n",
    "            # print(label, target, prediction, output)\n",
    "            if target == prediction:\n",
    "                correct_pred[label] += 1\n",
    "            else:\n",
    "                incorrect_pred[label].append(category_labels[int(prediction)])\n",
    "\n",
    "            total_pred[label] += 1\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:10s} is {accuracy:.1f} %')\n",
    "    print(f'\\tIncorrect predictions: {incorrect_pred[classname]}')\n",
    "print(f'Overall Accuracy: {(100 * float(sum(correct_pred.values()) / sum(total_pred.values()))):.3f}')\n",
    "del correct_pred\n",
    "del total_pred\n",
    "del correct_count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
